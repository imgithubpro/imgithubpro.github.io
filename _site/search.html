<!DOCTYPE html>
<html class="no-js">
  <head>
	<meta charset="utf-8">
	<title>Search | imgithubpro</title>
	<meta name="description" content="">
	<meta name="viewport" content="width=device-width, initial-scale=1">

	<!-- CSS -->
	<link rel="stylesheet" href="/assets/css/main.css">

	<!--Favicon-->
	<link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

	<!-- Canonical -->
	<link rel="canonical" href="/search.html">

	<!-- RSS -->
	<link rel="alternate" type="application/atom+xml" title="imgithubpro" href="/feed.xml" />

	<!-- Font Awesome -->
	<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

	<!-- Google Fonts -->
	
	<link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic" rel="stylesheet" type="text/css">
	

	<!-- KaTeX -->
	

	<!-- Google Analytics -->
	
	<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-118542017-1', 'auto');
	ga('send', 'pageview');
	</script>
	
</head>

  <body>
    <header class="site-header">
	<div class="branding">
		
		<a href="/">
			<img class="avatar" src="/assets/img/avatar.png" alt=""/>
		</a>
		
		<h1 class="site-title">
			<a href="/">imgithubpro</a>
		</h1>
	</div>
	<nav class="site-nav">
		<ul>
			
			
			
			
			
			
			<li>
				<a class="page-link" href="/about/">
					About
				</a>
			</li>
			
			
			
			<li>
				<a class="page-link" href="/categories/">
					Categories
				</a>
			</li>
			
			
			
			
			
			
			
			
			
			
			
			<li>
				<a class="page-link" href="/tags.html">
					tags
				</a>
			</li>
			
			
			
			
			<!-- Social icons from Font Awesome, if enabled  -->
			


<li>
	<a href="mailto:imgoooglepro@gmail.com" title="Email">
		<i class="fa fa-fw fa-envelope"></i>
	</a>
</li>













<li>
	<a href="https://github.com/imgithubpro" title="Follow on GitHub">
		<i class="fa fa-fw fa-github"></i>
	</a>
</li>




























            
            <!-- Search bar -->
            
            <li>
            <form action="/search.html" method="get">
                <input type="text" id="search-box" name="query" placeholder="Search" class="">
                <button type="submit" class="">
                    <i class="fa fa-fw fa-search"></i>
                </button>
            </form>
            </li>
            
		</ul>
	</nav>
    
</header>

    <div class="content">
      <article >
  <header style="background-image: url('/')">
    <h1 class="title">Search</h1>
    
  </header>
  <section class="post-content"><div class="search">
    <div id="search-results"></div>
    <p id="not-found" style="display: none">
        No results found.
    </p>
</div>


<script>
  window.store = {
    
      "elastic-2018-05-04-001-html": {
        "title": "Kibana 설치 및 시작하기",
        "tags": "elastic, kibana, install",
        "date": "May 4, 2018",
        "author": "",
        "category": "",
        "content": "Kibana 설치하기최신 버전 Kibana을 다운 : https://www.elastic.co/downloads/kibana$ tar -xzf kibana-6.2.4-linux-x86_64.tar.gz$ cd kibana-6.2.4-linux-x86_64/실행하기$ ./bin.kibanaKibana 설정  kibana-6.2.4-linux-x86_64/config/kibana.yml  원격 호스트에서 실행하는 경우 : server.host: \"0.0.0.0\" 수정  Elasticsearch url 확인 : elasticsearch.url: \"http://localhost:9200\"샘플 데이터 로드  데이터 집합을 accounts.json으로 저장  Shakespeare 테스트 데이터를 shakespeare.json으로 저장  임의로 생성된 테스트 로그 파일을 다운 받은 후 아래 명령으로 압축 해제    $ gunzip logs.jsonl.gz      맵핑 설정  맵핑은 인덱스 문서를 여러 논리적 그룹으로 나누고 필드의 특성을 지정  예를 들어 필드의 검색 가능성 또는 토큰화 여부(별개의 단어로 분리되는지)accounts 데이터는 맵핑 설정이 필요 없음.Shakespeare 데이터에 대한 맵핑 설정$ curl -H 'Content-Type: application/json' -XPUT http://localhost:9200/shakespeare -d '{ \"mappings\" : {  \"_default_\" : {   \"properties\" : {    \"speaker\" : {\"type\": \"string\", \"index\" : \"not_analyzed\" },    \"play_name\" : {\"type\": \"string\", \"index\" : \"not_analyzed\" },    \"line_id\" : { \"type\" : \"integer\" },    \"speech_number\" : { \"type\" : \"integer\" }   }  } }}';  speaker, play_name 필드는 분석되지 않는 문자열로 필드에 여러 단어가 있더라도 하나의 단위로 처리  line_id, speech_number 필드는 정수로그 데이터 집합에서는 geo_point 유형을 적용하여 로그의 위도/경도 쌍을 지리적 위치로 레이블하는 맵핑 추가  동일하게 파일 이름을 바꿔서 2015-05-18, 2015-05-19, 2015-05-20에 적용$ curl -H 'Content-Type: application/json' -XPUT http://localhost:9200/logstash-2015.05.18 -d '{  \"mappings\": {    \"log\": {      \"properties\": {        \"geo\": {          \"properties\": {            \"coordinates\": {              \"type\": \"geo_point\"            }          }        }      }    }  }}';bulk API로 데이터 집합 로드$ curl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/bank/account/_bulk?pretty' --data-binary @accounts.json$ curl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/shakespeare/_bulk?pretty' --data-binary @shakespeare.json$ curl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/_bulk?pretty' --data-binary @logs.jsonl로딩이 성공했는지 확인$ curl 'localhost:9200/_cat/indices?v'health status index               uuid                   pri rep docs.count docs.deleted store.size pri.store.sizeyellow open   logstash-2015.05.20 gB_6CZ7fTuq7cvebDqfsAw   5   1       4750            0     22.9mb         22.9mbyellow open   bank                8rRfeVYFQqO6wTrB5nfv4w   5   1       1000            0    483.1kb        483.1kbyellow open   logstash-2015.05.18 qnRb1CixSw6OqUtTHhQOkQ   5   1       4631            0     21.7mb         21.7mbyellow open   logstash-2015.05.19 _5tVsadAR7CqiSFOy5kwkA   5   1       4624            0     21.6mb         21.6mbgreen  open   .kibana             aVN70IAYSvWMX9VimBR0zw   1   0          5            1     29.7kb         29.7kbyellow open   shakespeare         r6sxO20BRmicCFm8PPU17A   5   1     110486            0     22.6mb         22.6mb인덱스 패턴 정의  Elasticsearch에 로드된 각 데이터 집합에는 인덱스 패턴이 있음  예를 들어, 로깅 예제의 경우 5월에 대한 인덱스 패턴은 logstash-2015.05*와 비슷한 형태  브라우저에서 localhost:5601로 이동  Management &gt; Index Patterns &gt; Create Index Pattern 선택          Index pattern에 shakes* 추가 &gt; Next &gt; Create index pattern 선택      Index pattern에 ba* 추가 &gt; Next &gt; Create index pattern 선택      Index pattern에 logstash* 추가 &gt; Next                  logstash 데이터의 경우 시계열 데이터가 있으므로 Time Filter에서 @timestamp 선택          Create index pattern 선택                    데이터 검색  Kibana의 데이터 검색은 Discover 메뉴를 사용  쿼리 표시줄에 Elasticsearch쿼리를 입력하여 데이터 검색  쿼리 표시줄 아래에는 인덱스 패턴이 드롭 다운 메뉴로 제공  선택한 인덱스 패턴에 따라 검색되는 인덱스가 결정  필드 이름과 값을 사용하여 검색을 구성  숫자 필드에는 &gt;, &lt;, = 같은 비교 연산자 사용 가능  여러 요소를 논리 연산자 AND, OR, NOT 으로 연결할 수 있음ba* 인덱스 패턴을 선택하고 쿼리 표시줄에 다음 문자열 입력특정 필드가 표시하려고 하는 경우 필드 목록 위에 커서를 놓고 포함할 필드 옆에 추가 단추 클릭데이터 시각화  Visualize 탭에서 데이터를 다양한 방식으로 볼 수 있음https://www.elastic.co/guide/kr/kibana/current/tutorial-visualizing.html대시보드  대시보드는 비주얼라이즈 탭에서 생성한 아이템들을 배치하고 공유할 수 있는 곳https://www.elastic.co/guide/kr/kibana/current/tutorial-dashboard.html",
        "url": "//elastic/2018/05/04/001.html"
      }
      ,
    
      "elastic-2018-05-03-001-html": {
        "title": "Elasticsearch 데이터 탐색하기",
        "tags": "elastic, elasticsearch, search",
        "date": "May 3, 2018",
        "author": "",
        "category": "",
        "content": "  샘플 데이터를 사용하여 Elasticsearch의 데이터 탐색 기능들을 테스트한다.데이터 탐색샘플 데이터 집합 로드  데이터 집합을 accounts.json으로 저장  해당 파일을 클러스터에 로드    $ curl -H \"Content-Type: application/json\" -XPOST 'localhost:9200/bank/account/_bulk?pretty&amp;refresh' --data-binary \"@accounts.json\"$ curl 'localhost:9200/_cat/indices?v'health status index    uuid                   pri rep docs.count docs.deleted store.size pri.store.sizeyellow open   bank     G1qJ7B-FTkS4Ut6R41dq9A   5   1       1000            0    648.2kb        648.2kb      검색 API  검색 실행 방법 : REST 요청 URL을 통해 검색 매개변수를 보내는 방법 &amp; REST 요청 본문을 통해 보내는 방법검색을 위한 REST API는 _search 엔드포인트에서 액세스 가능  bank 인덱스의 모든 문서를 반환$ curl -X GET \"localhost:9200/bank/_search?q=*&amp;sort=account_number:asc&amp;pretty\"{  \"took\" : 217,  \"timed_out\" : false,  \"_shards\" : {    \"total\" : 5,    \"successful\" : 5,    \"failed\" : 0  },  \"hits\" : {    \"total\" : 1000,    \"max_score\" : null,    \"hits\" : [      {        \"_index\" : \"bank\",        \"_type\" : \"account\",        \"_id\" : \"0\",        \"_score\" : null,        \"_source\" : {          \"account_number\" : 0,          \"balance\" : 16623,          \"firstname\" : \"Bradshaw\",          \"lastname\" : \"Mckenzie\",          \"age\" : 29,          \"gender\" : \"F\",          \"address\" : \"244 Columbus Place\",          \"employer\" : \"Euron\",          \"email\" : \"bradshawmckenzie@euron.com\",          \"city\" : \"Hobucken\",          \"state\" : \"CO\"        },        \"sort\" : [          0        ]      },      {        \"_index\" : \"bank\",\t...  q=* 매개변수로 모든 문서를 비교하여 일치 여부를 확인  sort=account_number:asc 매개변수는 각 문서의 account_number 필드를 기준으로 오름차순  응답 확인          took - 검색을 실행하는데 걸린 시간(밀리초)      timed_out - 검색의 시간 초과 여부      _shards - 검색한 샤드 수 및 검색에 성공/실패한 샤드 수      hits - 검색 결과      hits.total - 검색 조건과 일치하는 문서의 총 개수      hits.hits - 검색 결과의 실제 배열(기본 설정은 처음 10개 문서)      동일한 내용을 요청 본문 방식을 사용할 경우$ curl -X GET \"localhost:9200/bank/_search\"\\&gt;      -d '{&gt;        \"query\": { \"match_all\": {} },&gt;        \"sort\": [&gt;          { \"account_number\": \"asc\" }&gt;        ]&gt;      }'쿼리 언어 소개  QueryDSL이라는 JSON 스타일의 도메인 전용 언어 제공앞에서 봤던 마지막 예제$ curl -X GET \"localhost:9200/bank/_search\" -d '{\"query\" : { \"match_all\" : {} }}'  query 부분은 쿼리 정의가 무엇인지 알려줌  match_all 부분은 실행하려는 쿼리의 유형으로 지정된 인덱스의 모든 문서를 검색query 매개변수 외에 다른 배개변수 전달$ curl -X GET \"localhost:9200/bank/_search?pretty\"\\&gt;      -d '{&gt;        \"query\": { \"match_all\": {} },&gt;        \"size\": 1&gt;      }'  size가 지정되지 않으면 기본값은 10다음은 문서 11~20을 반환하는 예제$ curl -X GET \"localhost:9200/bank/_search?pretty\"\\&gt;      -d '{&gt;        \"query\": { \"match_all\": {} },&gt;        \"from\" : 10,&gt;        \"size\": 10&gt;      }'match_all 을 수행하고 잔액을 기준으로 10개(기본크기)를 내림차순 정렬$ curl -X GET \"localhost:9200/bank/_search?pretty\"\\&gt;      -d '{&gt;        \"query\": { \"match_all\": {} },&gt;        \"sort\": { \"balance\" : { \"order\" : \"desc\" } }&gt;      }'검색 실행  Query DSL 을 좀 더 자세히 살펴본다.  전체 JSON 문서가 모든 검색의 일부로 반환되며 이를 _source 필드라고 함_source 중 일부 필드만 반환되도록 테스트$ curl -X GET \"localhost:9200/bank/_search?pretty\"\\&gt;      -d '{&gt;        \"query\": { \"match_all\": {} },&gt;        \"_source\": [ \"account_number\", \"balance\" ]&gt;      }'  SQL SELECT FROM 필드와 비슷함match 쿼리 예제번호가 20인 계정$ curl -X GET \"localhost:9200/bank/_search?pretty\"\\&gt;      -d '{&gt;       \"query\": { \"match\": { \"account_number\" : 20 } }&gt;      }'주소에 “mill”이라는 용어가 있는 모든 계정$ curl -X GET \"localhost:9200/bank/_search?pretty\"\\&gt;      -d '{&gt;       \"query\": { \"match_phrase\": { \"address\" : \"mill lane\" } }&gt;      }'bool(Boolean)쿼리bool must 절에 지정된 모든 쿼리가 true가 되는 문서$ curl -X GET \"localhost:9200/bank/_search?pretty\"\\&gt;      -d '{&gt;       \"query\": {&gt;           \"bool\" : {&gt;               \"must\" : [&gt;                 { \"match\" : { \"address\" : \"mill\" } },&gt;                 { \"match\" : { \"address\" : \"lane\" } }&gt;               ]&gt;             }&gt;       }&gt;      }'  “mill”과 “lane”이 있는 모든 계정bool should 절에 지정된 쿼리 중 하나라도 true가 되는 문서$ curl -X GET \"localhost:9200/bank/_search?pretty\"\\&gt;      -d '{&gt;       \"query\": {&gt;           \"bool\" : {&gt;               \"should\" : [&gt;                 { \"match\" : { \"address\" : \"mill\" } },&gt;                 { \"match\" : { \"address\" : \"lane\" } }&gt;               ]&gt;             }&gt;       }&gt;      }'  “mill” 또는 “lane”이 있는 모든 계정must_not 사용$ curl -X GET \"localhost:9200/bank/_search?pretty\"\\&gt;      -d '{&gt;       \"query\": {&gt;           \"bool\" : {&gt;               \"must_not\" : [&gt;                 { \"match\" : { \"address\" : \"mill\" } },&gt;                 { \"match\" : { \"address\" : \"lane\" } }&gt;               ]&gt;             }&gt;       }&gt;      }'  must_not에 지정된 쿼리 중 어느 것도 true가 아닌 문서하나의 bool 쿼리 내에 must, should, must_not 절을 동시에 조합$ curl -X GET \"localhost:9200/bank/_search?pretty\"\\&gt;      -d '{&gt;       \"query\": {&gt;           \"bool\" : {&gt;               \"must\" : [&gt;                 { \"match\" : { \"age\" : \"40\" } }&gt;               ],&gt;               \"must_not\" : [&gt;                 { \"match\" : { \"state\" : \"ID\" } }&gt;               ]&gt;             }&gt;       }&gt;      }'필터 실행  bool 쿼리의 filter절을 테스트range쿼리$ curl -X GET \"localhost:9200/bank/_search?pretty\"\\&gt;      -d '{&gt;       \"query\": {&gt;           \"bool\" : {&gt;               \"must\" : { \"match_all\" : {} },&gt;               \"filter\" : {&gt;                   \"range\" : {&gt;                       \"balance\" : {&gt;                           \"gte\" : 20000,&gt;                           \"lte\" : 30000&gt;                       }&gt;                   }&gt;               }&gt;             }&gt;       }&gt;      }'집계 실행  SQL GROUP BY 및 SQL 집계 기능과 유사  하나의 응답에서 검색과 동시에 그와 별도로 집계 결과 반환 가능주를 기준으로 그룹화하고 내림차순(기본 설정)으로 상위 10개(기본 설정) 주 반환$ curl -X GET \"localhost:9200/bank/_search?pretty\"\\&gt;      -d '{&gt;          \"size\" : 0,&gt;         \"aggs\" : {&gt;             \"group_by_state\" : {&gt;                 \"terms\" : {&gt;                     \"field\" : \"state.keyword\"&gt;                 }&gt;             }&gt;         }&gt;      }'개념상 다음 SQL 과 비슷SELECT state, COUNT(*) FROM bank GROUP BY state ORDER BY COUNT(*) DESC다음은 응답의 일부\"aggregations\" : {    \"group_by_state\" : {      \"doc_count_error_upper_bound\" : 20,      \"sum_other_doc_count\" : 770,      \"buckets\" : [        {          \"key\" : \"ID\",          \"doc_count\" : 27        },        {          \"key\" : \"TX\",          \"doc_count\" : 27        },        {          \"key\" : \"AL\",          \"doc_count\" : 25        },  응답에서 집계 결과만 보고 검색 결과는 표시하지 않기 위해 size=0으로 설정앞의 집계를 바탕으로 주별 평균 계좌 잔액을 내림차순으로 정렬calhost:9200/bank/_search?pretty\"\\&gt;      -d '{&gt;          \"size\" : 0,&gt;         \"aggs\" : {&gt;             \"group_by_state\" : {&gt;                 \"terms\" : {&gt;                     \"field\" : \"state.keyword\",&gt;                     \"order\" : {&gt;                         \"average_balance\" : \"desc\"&gt;                     }&gt;                 },&gt;                 \"aggs\" : {&gt;                     \"average_balance\" : {&gt;                         \"avg\" : {&gt;                             \"field\" : \"balance\"&gt;                         }&gt;                     }&gt;                 }&gt;             }&gt;         }&gt;      }'연령대(20-29, 30-39, 40-49)를 기준으로, 성별로 그룹화하고 연령대, 성별 기준 평균 계정 잔액$ curl -X GET \"localhost:9200/bank/_search?pretty\"\\&gt;      -d '{&gt;           \"size\": 0,&gt;           \"aggs\": {&gt;             \"group_by_age\": {&gt;               \"range\": {&gt;                 \"field\": \"age\",&gt;                 \"ranges\": [&gt;                   {&gt;                     \"from\": 20,&gt;                     \"to\": 30&gt;                   },&gt;                   {&gt;                     \"from\": 30,&gt;                     \"to\": 40&gt;                   },&gt;                   {&gt;                     \"from\": 40,&gt;                     \"to\": 50&gt;                   }&gt;                 ]&gt;               },&gt;               \"aggs\": {&gt;                 \"group_by_gender\": {&gt;                   \"terms\": {&gt;                     \"field\": \"gender.keyword\"&gt;                   },&gt;                   \"aggs\": {&gt;                     \"average_balance\": {&gt;                       \"avg\": {&gt;                         \"field\": \"balance\"&gt;                       }&gt;                     }&gt;                   }&gt;                 }&gt;               }&gt;             }&gt;           }&gt;         }'",
        "url": "//elastic/2018/05/03/001.html"
      }
      ,
    
      "elastic-2018-05-02-001-html": {
        "title": "Elasticsearch REST API 시작하기",
        "tags": "elastic, elasticsearch",
        "date": "May 2, 2018",
        "author": "",
        "category": "",
        "content": "  REST API를 사용하여 Elasticsearch의 각 기능을 살펴본다.클러스터 API  curl을 사용해서 테스트 클러스터 상태$ curl -X GET \"localhost:9200/_cat/health?v\"epoch      timestamp cluster       status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent1525159681 16:28:01  elasticsearch green           1         1      0   0    0    0        0             0                  -                100.0%  status : 클러스터의 상태 값은 녹색/노란색/빨간색 중 하나          green : 클러스터 정상 작동      yellow : 모든 데이터가 사용 가능한 상태이지만 일부 리플리카가 아직 배정되지 않은 상태(클러스터는 정상 작동 중)      red : 어떤 이유로 일부 데이터가 사용할 수 없는 상태      클러스터 노드 목록$ curl -X GET \"localhost:9200/_cat/nodes?v\"ip        heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name127.0.0.1           12          97   1    0.14    0.08     0.11 mdi       *      FxRG3ga인덱스 확인$ curl -X GET \"localhost:9200/_cat/indices?v\"health status index uuid pri rep docs.count docs.deleted store.size pri.store.size  아직 클러스터에 인덱스가 없는 경우인덱스 생성$ curl -X PUT \"localhost:9200/customer?pretty\"{\t\"acknowledged\" : true,\t\"shards_acknowledged\" : true}$ curl -X GET \"localhost:9200/_cat/indices?v\"health status index    uuid                   pri rep docs.count docs.deleted store.size pri.store.sizeyellow open   customer TStBp1JvQ3ii3xvAZmRAlw   5   1          0            0       650b           650b  PUT을 통해 “customer”라는 인덱스 생성  마지막 pretty를 추가할 경우, JSON응답이 있다면 pretty-print 수행  두 번째 명령의 결과를 보면 customer라는 인덱스 1개가 있고 이 인덱스는 기본 샤드 5개, 리플리카 1개로 포함된 다큐먼트는 0개  customer 인덱스는 노란색 상태 태그로 표시          Elasticsearch에서는 기본적으로 인덱스에 대해 리플리카를 1개 생성      이 리플리카가 하나의 노드에서 실행 중이므로 고가용성을 위해 배정될 수 없음      나중에 이 리플리카가 두 번째 노드에 배정 시 녹색으로 변경      다큐먼트 인덱싱 및 쿼리Elasticsearch에서 데이터에 액세스하는 패턴&lt;REST Verb&gt; /&lt;Index&gt;/&lt;Type&gt;/&lt;ID&gt;다큐먼트 추가$ curl -X PUT \"localhost:9200/customer/external/1?pretty\"\\&gt;      -d '{\"name\":\"John Doe\"}'{  \"_index\" : \"customer\",  \"_type\" : \"external\",  \"_id\" : \"1\",  \"_version\" : 1,  \"result\" : \"created\",  \"_shards\" : {    \"total\" : 2,    \"successful\" : 1,    \"failed\" : 0  },  \"created\" : true}  customer 색인 및 external 타입에 새 고객 문서가 생성  Elasticsearch는 문서를 인덱싱하기 전에 명시적으로 인덱스를 생성할 필요가 없음  앞의 예에서 customer 인덱스가 없으면 자동으로 생성방금 인덱싱한 문서 검색$ curl -X GET \"localhost:9200/customer/external/1?pretty\"{  \"_index\" : \"customer\",  \"_type\" : \"external\",  \"_id\" : \"1\",  \"_version\" : 1,  \"found\" : true,  \"_source\" : {    \"name\" : \"John Doe\"  }}  found : 요청된 ID 1에 해당하는 문서를 찾았다고 알려줌  _source : JSON 문서 전체를 반환인덱스 삭제$ curl -X DELETE \"localhost:9200/customer?pretty\"{  \"acknowledged\" : true}$ curl -X GET \"localhost:9200/_cat/indices?v\"health status index uuid pri rep docs.count docs.deleted store.size pri.store.size데이터 수정  데이터는 인덱싱/업데이트/삭제하는 시점부터 검색 결과에 나타나는 시점까지 1초 정도 소요(새로고침 간격)문서 인덱싱/대체앞서 단일 문서 인덱싱 예제를 다시 실행$ curl -X PUT \"localhost:9200/customer/external/1?pretty\"\\&gt;       -d '{\"name\":\"John Doe\"}'{  \"_index\" : \"customer\",  \"_type\" : \"external\",  \"_id\" : \"1\",  \"_version\" : 1,  \"result\" : \"created\",  \"_shards\" : {    \"total\" : 2,    \"successful\" : 1,    \"failed\" : 0  },  \"created\" : true}문서의 내용을 바꿔서 동일하게 다시 실행$ curl -X PUT \"localhost:9200/customer/external/1?pretty\"\\&gt;          -d '{\"name\":\"Jane Doe\"}'{  \"_index\" : \"customer\",  \"_type\" : \"external\",  \"_id\" : \"1\",  \"_version\" : 2,  \"result\" : \"updated\",  \"_shards\" : {    \"total\" : 2,    \"successful\" : 1,    \"failed\" : 0  },  \"created\" : false}  ID가 1인 문서의 name이 “John doe”에서 “Jane Doe”로 바뀜ID없이 인덱싱하는 경우$ curl -X POST \"localhost:9200/customer/external?pretty\"\\&gt;          -d '{\"name\":\"Jane Doe\"}'{  \"_index\" : \"customer\",  \"_type\" : \"external\",  \"_id\" : \"AWMb2NtytvPg5vPfDWWF\",  \"_version\" : 1,  \"result\" : \"created\",  \"_shards\" : {    \"total\" : 2,    \"successful\" : 1,    \"failed\" : 0  },  \"created\" : true}  ID를 지정하지 않으면 PUT대신 POST 사용문서 업데이트  문서를 업데이트하면 기존 문서가 삭제되고 새 문서를 인덱싱한 후 여기에 업데이트 적용$ curl -X POST \"localhost:9200/customer/external/1/_update?pretty\"\\&gt;          -d '{\"doc\":{\"name\":\"Jane Doe\", \"age\":20}}'{  \"_index\" : \"customer\",  \"_type\" : \"external\",  \"_id\" : \"1\",  \"_version\" : 3,  \"result\" : \"updated\",  \"_shards\" : {    \"total\" : 2,    \"successful\" : 1,    \"failed\" : 0  }}스크립트를 통한 업데이트$ curl -X POST \"localhost:9200/customer/external/1/_update?pretty\"\\&gt;          -d '{\"script\" : \"ctx._source.age += 5\"}'{  \"_index\" : \"customer\",  \"_type\" : \"external\",  \"_id\" : \"1\",  \"_version\" : 4,  \"result\" : \"updated\",  \"_shards\" : {    \"total\" : 2,    \"successful\" : 1,    \"failed\" : 0  }}$ curl -X GET \"localhost:9200/customer/external/1?pretty\"{  \"_index\" : \"customer\",  \"_type\" : \"external\",  \"_id\" : \"1\",  \"_version\" : 4,  \"found\" : true,  \"_source\" : {    \"name\" : \"Jane Doe\",    \"age\" : 25  }}  ctx._source는 업데이트하려는 현재 소스 문서문서 삭제$ curl -X DELETE \"localhost:9200/customer/external/1?pretty\"{  \"found\" : true,  \"_index\" : \"customer\",  \"_type\" : \"external\",  \"_id\" : \"1\",  \"_version\" : 5,  \"result\" : \"deleted\",  \"_shards\" : {    \"total\" : 2,    \"successful\" : 1,    \"failed\" : 0  }}배치 처리간단한 예로 하나의 벌크 호출로 문서 2개를 인덱싱$ curl -X POST \"localhost:9200/customer/external/_bulk?pretty\"\\&gt;  -d '{\"index\":{\"_id\":\"1\"}}&gt; {\"name\":\"John Doe\"}&gt; {\"index\":{\"_id\":\"2\"}}&gt; {\"name\":\"Jane Doe\"}'{  \"took\" : 99,  \"errors\" : false,  \"items\" : [    {      \"index\" : {        \"_index\" : \"customer\",        \"_type\" : \"external\",        \"_id\" : \"1\",        \"_version\" : 1,        \"result\" : \"created\",        \"_shards\" : {          \"total\" : 2,          \"successful\" : 1,          \"failed\" : 0        },        \"created\" : true,        \"status\" : 201      }    }  ]}업데이트와 삭제를 배치로 처리$ curl -X POST \"localhost:9200/customer/external/_bulk?pretty\"\\&gt; -d '{\"update\":{\"_id\":\"1\"}}&gt; {\"doc\": { \"name\": \"John Doe becomes Jane Doe\" } }&gt; {\"delete\":{\"_id\":\"2\"}}'{  \"took\" : 26,  \"errors\" : false,  \"items\" : [    {      \"update\" : {        \"_index\" : \"customer\",        \"_type\" : \"external\",        \"_id\" : \"1\",        \"_version\" : 2,        \"result\" : \"updated\",        \"_shards\" : {          \"total\" : 2,          \"successful\" : 1,          \"failed\" : 0        },        \"status\" : 200      }    }  ]}출처 : https://www.elastic.co/guide/kr/elasticsearch/reference/current/gs-exploring-cluster.html",
        "url": "//elastic/2018/05/02/001.html"
      }
      ,
    
      "elastic-2018-05-01-001-html": {
        "title": "Elasticsearch 시작하기",
        "tags": "elastic, elasticsearch, install",
        "date": "May 1, 2018",
        "author": "",
        "category": "",
        "content": "  Elasticsearch의 기본개념에 대해 알아보고 CentOS 7에 설치해보자.Elasticsearch 기본개념NRT(Near Realtime)  Elasticsearch는 NRT 검색 플랫폼클러스터  하나 이상의 노드(서버)가 모인 것  고유한 이름으로 식별되며 기본 이름은 “elasticsearch”노드  클러스터에 포함된 단일 서버인덱스  단일 클러스터에 원하는 개수의 인덱스 정의 가능  RDB에 database에 해당타입  하나의 인덱스에서 하나 이상의 타입 정의 가능  RDB에 table에 해당도큐먼트  도큐먼트는 인덱싱할 수 있는 기본 정보 단위  JSON형태  하나의 인덱스/타입에 원하는 개수의 도큐먼트 저장 가능  RDB에 row에 해당샤드 &amp; 리플리카  인덱스를 샤드라는 조각으로 분할하여 저장  샤드에 대한 복사본을 리플리카라고 함  인덱스가 생성된 다음 리플리카는 언제든 변경 가능하지만, 샤드 수는 사후 변경 불가Elasticsearch 설치  Elasticsearch는 Java 8 이상이 필요  CentOS 7 기준 설치Java 설치$ sudo yum localinstall -y jdk-8u77-linux-x64.rpm$ cd /usr/java$ sudo ln -s /usr/java/default java8$ java -versionjava version \"1.8.0_77\"Java(TM) SE Runtime Environment (build 1.8.0_77-b03)Elasticsearch 설치$ curl -x http://proxy.yourhost:port -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.4.3.tar.gz$ tar -xvf elasticsearch-5.4.3.tar.gz[참고] 메모리가 부족한 경우 elasticsearch-5.4.3/config/jvm.options 에서 heap size 수정-Xms1g-Xmx1gElasticsearch 실행  “FxRG3ga”라는 노드가 실행    $ cd elasticsearch-5.4.3/bin$ ./elasticsearch[2018-05-01T01:25:58,835][INFO ][o.e.e.NodeEnvironment    ] [FxRG3ga] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [45gb], net total_space [49.9gb], spins? [unknown], types [rootfs][2018-05-01T01:25:58,837][INFO ][o.e.e.NodeEnvironment    ] [FxRG3ga] heap size [1007.3mb], compressed ordinary object pointers [true][2018-05-01T01:25:58,839][INFO ][o.e.n.Node               ] node name [FxRG3ga] derived from node ID [FxRG3gaDRHWfqpaQR6noNQ]; set [node.name] to override[2018-05-01T01:25:58,840][INFO ][o.e.n.Node               ] version[5.4.3], pid[25964], build[eed30a8/2017-06-22T00:34:03.743Z], OS[Linux/3.10.0-693.21.1.el7.x86_64/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_77/25.77-b03][2018-05-01T01:25:58,840][INFO ][o.e.n.Node               ] JVM arguments [-Xms1g, -Xmx1g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -XX:+DisableExplicitGC, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -Djdk.io.permissionsUseCanonicalPath=true, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Dlog4j.skipJansi=true, -XX:+HeapDumpOnOutOfMemoryError, -Des.path.home=/home/deploy/tmp/elasticsearch-5.4.3][2018-05-01T01:26:02,151][INFO ][o.e.p.PluginsService     ] [FxRG3ga] loaded module [aggs-matrix-stats][2018-05-01T01:26:02,152][INFO ][o.e.p.PluginsService     ] [FxRG3ga] loaded module [ingest-common][2018-05-01T01:26:02,153][INFO ][o.e.p.PluginsService     ] [FxRG3ga] loaded module [lang-expression][2018-05-01T01:26:02,153][INFO ][o.e.p.PluginsService     ] [FxRG3ga] loaded module [lang-groovy][2018-05-01T01:26:02,153][INFO ][o.e.p.PluginsService     ] [FxRG3ga] loaded module [lang-mustache][2018-05-01T01:26:02,153][INFO ][o.e.p.PluginsService     ] [FxRG3ga] loaded module [lang-painless][2018-05-01T01:26:02,153][INFO ][o.e.p.PluginsService     ] [FxRG3ga] loaded module [percolator][2018-05-01T01:26:02,154][INFO ][o.e.p.PluginsService     ] [FxRG3ga] loaded module [reindex][2018-05-01T01:26:02,154][INFO ][o.e.p.PluginsService     ] [FxRG3ga] loaded module [transport-netty3][2018-05-01T01:26:02,154][INFO ][o.e.p.PluginsService     ] [FxRG3ga] loaded module [transport-netty4][2018-05-01T01:26:02,156][INFO ][o.e.p.PluginsService     ] [FxRG3ga] no plugins loaded[2018-05-01T01:26:04,213][INFO ][o.e.d.DiscoveryModule    ] [FxRG3ga] using discovery type [zen][2018-05-01T01:26:05,382][INFO ][o.e.n.Node               ] initialized[2018-05-01T01:26:05,382][INFO ][o.e.n.Node               ] [FxRG3ga] starting ...[2018-05-01T01:26:05,601][INFO ][o.e.t.TransportService   ] [FxRG3ga] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}[2018-05-01T01:26:08,729][INFO ][o.e.c.s.ClusterService   ] [FxRG3ga] new_master {FxRG3ga}{FxRG3gaDRHWfqpaQR6noNQ}{bDF_nP_QR2qUgN_fZS1rgQ}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-elected-as-master ([0] nodes joined)[2018-05-01T01:26:08,784][INFO ][o.e.h.n.Netty4HttpServerTransport] [FxRG3ga] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}[2018-05-01T01:26:08,793][INFO ][o.e.g.GatewayService     ] [FxRG3ga] recovered [0] indices into cluster_state[2018-05-01T01:26:08,791][INFO ][o.e.n.Node               ] [FxRG3ga] started      클러스터 또는 노드 이름 설정./elasticsearch -Ecluster.name=my_cluster_name -Enode.name=my_node_name실행 확인$ curl http://localhost:9200/{  \"name\" : \"FxRG3ga\",  \"cluster_name\" : \"elasticsearch\",  \"cluster_uuid\" : \"zZzodj6uRA2p21N9BNAkpQ\",  \"version\" : {    \"number\" : \"5.4.3\",    \"build_hash\" : \"eed30a8\",    \"build_date\" : \"2017-06-22T00:34:03.743Z\",    \"build_snapshot\" : false,    \"lucene_version\" : \"6.5.1\"  },  \"tagline\" : \"You Know, for Search\"}출처 : https://www.elastic.co/guide/kr/elasticsearch/reference/current/getting-started.html",
        "url": "//elastic/2018/05/01/001.html"
      }
      ,
    
      "linux-2018-04-29-002-html": {
        "title": "VirtualBox 설치하기",
        "tags": "centos, virtualbox, install",
        "date": "April 29, 2018",
        "author": "",
        "category": "",
        "content": "  CentOS 7 에 VirtualBox 설치해보자.VirtualBox repo 추가$ cd /etc/yum.repos.d/$ sudo wget http://download.virtualbox.org/virtualbox/rpm/el/virtualbox.repo  proxy가 있는 경우 : -e use_proxy=yes -e http_proxy=http://proxy.yourhost:port 추가$ sudo yum repolist$ yum list VirtualBox*  원하는 VirtualBox 버전 선택 VirtualBox install$ sudo yum install VirtualBox-5.0  yum proxy 설정 : /etc/yum.conf에 proxy=http://proxy.yourhost:port 추가[참고] 의존성 라이브러리 rpm으로 직접 설치$ rpm -ivh 패키지명",
        "url": "//linux/2018/04/29/002.html"
      }
      ,
    
      "docker-2018-04-29-001-html": {
        "title": "도커 서비스 구성하기",
        "tags": "docker, devops, service, compose",
        "date": "April 29, 2018",
        "author": "",
        "category": "",
        "content": "  docker-compose.yml 을 사용하여 도커 서비스를 구성하고 실행해보자.도커의 서비스란?  “프로덕션 컨테이너”로 실제 서비스의 기능 블럭  어떤 포트들을 사용해야 하는지 얼마나 많은 컨테이 복제본들을 실행해야 하는지 정의  서비스 확장 시, 프로세스의 서비스는 해당 소프트웨어를 실행하는 컨테이너 인스턴스의 수 증가  도커는 서비스 확장과 실행을 위해 docker-compose.yml 사용docker-compose.yml 파일 작성하기docker-compose 설치Linux 기준 Compose 설치  proxy를 사용하는 경우: -x http://proxy.yourhost:port 를 추가$ sudo curl -L https://github.com/docker/compose/releases/download/1.21.0/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose$ sudo chmod +x /usr/local/bin/docker-compose$ docker-compose --version # testdocker-compose.yml  docker-compose.yml파일은 도커 컨테이너들이 서비스에서 어떻게 작동하는지 정의하는 YAML 파일  앞에서 만들었던 username/repo:tag 이미지를 사용해서 실습    version: \"3\"services:web:  # replace username/repo:tag with your name and image details  image: username/repo:tag  deploy:    replicas: 5    resources:      limits:        cpus: \"0.1\" # 10% of the CPU        memory: 50M    restart_policy:      condition: on-failure  ports:    - \"80:80\"  networks:    - webnetnetworks:webnet:          새로운 로드밸런스된 앱을 실행하기docker stack deploy 명령얼 사용하기 전에 아래 명령 수행$ docker swarm initgetstartedlab 이라는 이름으로 앱을 실행$ docker statck deploy -c docker-compose.yml getstartedlab  우리가 설정가 앱은 각 호스트당 배포된 이미지가 5개의 컨테이너 인스턴스로 실행되는 싱글 서비스 스택으로 구성서비스 아이디 확인$ docker service ls  web 서비스의 결과를 확인해보면 서비스의 이름은 getstartedlab_web으로 출력  서비스에서 실행되는 각 단일 컨테이너가 테스크  테스크는 docker-compose.yml파일에 정의한 replicas 갯수만큼 순차적으로 증가하는 유니크한 아이디를 가짐해당 서비스의 테스크 아이디 확인$ docker service ps getstartedlab_web필터 없이 모든 서비스 확인$ docker container ls -q인스턴스 결과 확인$ curl -4 http://localhost  컨테이너는 각 요청마다 라운드로빈 방식으로 선택앱 스케일 수정docker-compose.yml 파일의 replicas를 수정 후에 docker statck deploy 명령으로 다시 실행$ docker stack deploy -c docker-compose.yml getstartedlab  도커는 해당 스택을 다운시키거나 킬 시킬필요 없이 업데이트앱 종료docker stack rm명령으로 앱 다운$ docker stack rm getstartedlabswarm 다운$ docker swarm leave --force사용한 명령어 정리docker stack ls                                            # List stacks or appsdocker stack deploy -c &lt;composefile&gt; &lt;appname&gt;  # Run the specified Compose filedocker service ls                 # List running services associated with an appdocker service ps &lt;service&gt;                  # List tasks associated with an appdocker inspect &lt;task or container&gt;                   # Inspect task or containerdocker container ls -q                                      # List container IDsdocker stack rm &lt;appname&gt;                             # Tear down an applicationdocker swarm leave --force      # Take down a single node swarm from the manager",
        "url": "//docker/2018/04/29/001.html"
      }
      ,
    
      "docker-2018-04-28-001-html": {
        "title": "도커를 이용한 간단한 앱 만들기",
        "tags": "docker, devops",
        "date": "April 28, 2018",
        "author": "",
        "category": "",
        "content": "  Dockerfile을 사용하여 컨테이너를 정의하여 실행해보자.생성한 이미지들을 리모트 저장소에 저장하고, 해당 이미지를 사용한다.도커 파일을 이용한 컨테이너 정의  Dockerfile은 컨테이너의 환경 설정을 정의  디스크나 네트워크 인터페이스에 대한 접근을 가상화하여 환경 설정에 정의하여 시스템으로부터 분리  Dockerfile을 통해서 정의한 app은 어디서나 동일하게 실행 가능도커파일 정의하기  빈 디렉토리를 생성하여 그 안에 아래 3개의 파일들을 입력Dockerfile# Use an official Python runtime as a parent imageFROM python:2.7-slim# Set the working directory to /appWORKDIR /app# Copy the current directory contents into the container at /appADD . /app# Install any needed packages specified in requirements.txtRUN pip install --trusted-host pypi.python.org -r requirements.txt# Make port 80 available to the world outside this containerEXPOSE 80# Define environment variableENV NAME World# Run app.py when the container launchesCMD [\"python\", \"app.py\"]requirements.txtFlaskRedisapp.pyfrom flask import Flaskfrom redis import Redis, RedisErrorimport osimport socket# Connect to Redisredis = Redis(host=\"redis\", db=0, socket_connect_timeout=2, socket_timeout=2)app = Flask(__name__)@app.route(\"/\")def hello():    try:        visits = redis.incr(\"counter\")    except RedisError:        visits = \"&lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;\"    html = \"&lt;h3&gt;Hello {name}!&lt;/h3&gt;\" \\           \"&lt;b&gt;Hostname:&lt;/b&gt; {hostname}&lt;br/&gt;\" \\           \"&lt;b&gt;Visits:&lt;/b&gt; {visits}\"    return html.format(name=os.getenv(\"NAME\", \"world\"), hostname=socket.gethostname(), visits=visits)if __name__ == \"__main__\":    app.run(host='0.0.0.0', port=80)앱 빌드하기빌드를 위한 디렉토리 구조$ lsDockerfile\t\tapp.py\t\t\trequirements.txtdocker build 명령을 통해  Dockerfile로부터 이미지를 빌드  -t옵션을 사용해서 tag로 사용할 이름을 설정docker build -t friendlyhello .생성된 이미지 확인$ docker image lsREPOSITORY                TAG                 IMAGE ID            friendlyhello             latest              c2e684e3c029    [참고] 프록시 서버 설정  해당 서버 앞에 프록시 서버가 설정된 경우 ENV 명령을 통해서 Dockerfile에 해당 프록시 설정 추가  위에 Dockerfile에 EVN 설정 부분에 이어서 추가    # Set proxy server, replace host:port with values for your serversENV http_proxy host:portENV https_proxy host:port          앱 실행하기docker run 명령을 통해 앱을 실행  -p옵션을 통해 머신의 4000 포트와 컨테이너의 80 포트를 매핑docker run -p 4000:80 friendlyhello # &lt;host port&gt;:&lt;container port&gt;  파이썬의 해당 앱은 컨테이너 안에서 http://0.0.0.0:80에서 서비스  http://localhost:4000 URL로 컨테이너는 서비스하며 실제 80포트와의 매핑은 숨겨짐  CTRL+C로 종료해당 페이지 확인$ curl http://localhost:4000&lt;h3&gt;Hello World!&lt;/h3&gt;&lt;b&gt;Hostname:&lt;/b&gt; 07e1a6d098ac&lt;br/&gt;&lt;b&gt;Visits:&lt;/b&gt; &lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;앱을 백그라운드로 실행  -d옵션을 사용하면 detached mode로 데몬 상태로 실행docker run -d -p 4000:80 friendlyhello실행중인 컨테이너 확인$ docker container lsCONTAINER ID        IMAGE               COMMAND             CREATED07e1a6d098ac        friendlyhello       \"python app.py\"     About an hour ago해당 컨테이너 정지  CONTAINER ID를 사용해서 docker container stop 으로 해당 프로세스를 정지$ docker container stop 07e1a6d098ac07e1a6d098ac이미지 공유하기  생성한 이미지를 다른 곳에서 실행하기 위해 도커 레지스트리 사용  도커 레지스트리는 리포지토리들의 집합  리포지토리는 이미지들의 집합  도커 레지스트리 이외에도 도커는 도커 허브를 제공  도커 허브는 도커가 제공하는 공개된 이미지 저장소로 회원 가입으로 사용 가능도커 아이디로 로그인하기https://cloud.docker.com 을 통해서 회원 가입 후에 해당 아이디를 통해 로컬 머신에서 공개된 레지스트리로 로그인$ docker login이미지 태그하기레지스트리에 리포지토리 형식 : username/repository:tagdocker tag image username/repository:tag사용 예시docker tag friendlyhello john/get-started:part2docker image ls 로 새롭게 태그된 이미지 확인$ docker image lsREPOSITORY                TAG                 IMAGE ID            CREATED             SIZEfriendlyhello             latest              c2e684e3c029        29 hours ago        151 MBjohn/get-started          part2               c2e684e3c029        29 hours ago        151 MB이미지 업로드하기리포지토리에 태그된 이미지를 업로드 : Docker Hub 에서 확인 가능docker push username/repository:tag리모트 리포지토리 이미지로 실행하기docker run 으로 앱 실행 시  로컬 머신에 해당 이미지가 없는 경우 도커는 리포지토리에서 pull &amp; rundocker run -p 4000:80 username/repository:tag사용한 명령어 정리docker build -t friendlyhello .  # Create image using this directory's Dockerfiledocker run -p 4000:80 friendlyhello  # Run \"friendlyname\" mapping port 4000 to 80docker run -d -p 4000:80 friendlyhello         # Same thing, but in detached modedocker container ls                                # List all running containersdocker container ls -a             # List all containers, even those not runningdocker container stop &lt;hash&gt;           # Gracefully stop the specified containerdocker container kill &lt;hash&gt;         # Force shutdown of the specified containerdocker container rm &lt;hash&gt;        # Remove specified container from this machinedocker container rm $(docker container ls -a -q)         # Remove all containersdocker image ls -a                             # List all images on this machinedocker image rm &lt;image id&gt;            # Remove specified image from this machinedocker image rm $(docker image ls -a -q)   # Remove all images from this machinedocker login             # Log in this CLI session using your Docker credentialsdocker tag &lt;image&gt; username/repository:tag  # Tag &lt;image&gt; for upload to registrydocker push username/repository:tag            # Upload tagged image to registrydocker run username/repository:tag                   # Run image from a registry",
        "url": "//docker/2018/04/28/001.html"
      }
      ,
    
      "docker-2018-04-27-001-html": {
        "title": "도커 설치 &amp; hello world",
        "tags": "docker, devops",
        "date": "April 27, 2018",
        "author": "",
        "category": "",
        "content": "  CentOS 7 기준으로 도커를 설치하고, 간단한 hello-world 예제 실행해보자.도커란 무엇인가컨테이너 기반으로 애플리케이션을 개발, 배포, 실행할 수 있게 해주는 플랫폼이미지와 컨테이너이미지  애플리케이션이 실행되는데 필요한 모든 것이 포함된 실행가능한 패키지  코드, 런타임 라이브러리, 환경 변수, 설정 파일 등을 포함컨테이너  컨테이너는 이미지를 실행한 상태  이미지의 런타임 인스턴스  docker ps 명령을 통해서 실행중인 컨테이너 리스트 확인컨테이너와 가상머신컨테이너  리눅스에서 호스트 머신의 커널을 다른 컨테이너들과 공유하며 네이티브로 실행  개별 프로세스로 실행  애플리케이션에 필요한 메모리만을 사용하여 가벼움가상머신(Virtual machine)  하이퍼바이저를 통해 호스트 리소스에 대한 가상 액세스 권한을 가진 “게스트” 운영 체제를 실행  일반적으로 애플리케이션에서 필요한 것보다 많은 리소스 사용설치하기os 확인$ grep . /etc/*-release/etc/centos-release:CentOS Linux release 7.4.1708 (Core)CentOS 7 기준sudo yum install docker버전 확인$ docker -v # --versionDocker version 1.13.1, build 774336d/1.13.1sudo 없이 docker 명령어 실행을 위한 docker 그룹 설정$ sudo groupadd docker$ sudo gpasswd -a ${USER} docker$ sudo service docker restarthello-world이미지 리스트$ docker image lsREPOSITORY              TAG                 IMAGE ID            CREATED             SIZEhello-world 실행$ docker run hello-world  이미지기 없는 경우 자동으로 pull 된 후에 실행  이미지 리스트에 다운된 hello-world가 추가$ docker image lsREPOSITORY              TAG                 IMAGE ID            CREATED             SIZEdocker.io/hello-world   latest              e38bc07ac18e        2 weeks ago         1.85 kB컨테이너 리스트$ docker container ls # --all or -aq사용한 명령어 정리## List Docker CLI commandsdockerdocker container --help## Display Docker version and infodocker --versiondocker versiondocker info## Execute Docker imagedocker run hello-world## List Docker imagesdocker image ls## List Docker containers (running, all, all in quiet mode)docker container lsdocker container ls --alldocker container ls -aq참고 : https://docs.docker.com/get-started/",
        "url": "//docker/2018/04/27/001.html"
      }
      
    
  };
</script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/0.7.1/lunr.min.js"></script>
<script src="/assets/js/search.js"></script>
</section>
</article>

    </div>
    


<footer class="site-footer">
	<p class="text">Powered by <a href="https://jekyllrb.com/">Jekyll</a> with <a href="https://github.com/rohanchandra/type-theme">Type Theme</a>
</p>
</footer>


  </body>
</html>
